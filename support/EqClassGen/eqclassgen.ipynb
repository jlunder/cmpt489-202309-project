{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import functools, random, re\n",
    "\n",
    "import synthast as ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing \"# Multiply(Ite(Eq(x, 1), Multiply(x, x), Multiply(y, x)), Add(Add(z, z), 2))\":\n",
      "  expr: Multiply(Ite(Eq(x, 1), Multiply(x, x), Multiply(y, x)), Add(Add(z, z), 2))\n"
     ]
    }
   ],
   "source": [
    "test_fn = '../../test-data/phase2/0308.txt'\n",
    "with open(test_fn) as f:\n",
    "    print('parsing \"%s\":' % (f.readline().strip(),))\n",
    "expr = ast.parse_examples(test_fn)\n",
    "print('  expr: %s' % (expr,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left(2 z + 2\\right) \\left(\\begin{cases} x^{2} & \\text{for}\\: x = 1 \\\\x y & \\text{otherwise} \\end{cases}\\right)$"
      ],
      "text/plain": [
       "(2*z + 2)*Piecewise((x**2, Eq(x, 1)), (x*y, True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr.to_sym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450222\n",
      "1\n",
      "2\n",
      "3\n",
      "x\n",
      "y\n",
      "z\n",
      "Add(1, 1)\n",
      "Add(1, 2)\n",
      "Add(1, 3)\n",
      "Add(1, x)\n",
      "...\n",
      "Ite(Eq(z, z), Multiply(z, z), Multiply(z, 2))\n",
      "Ite(Eq(z, z), Multiply(z, z), Multiply(z, 3))\n",
      "Ite(Eq(z, z), Multiply(z, z), Multiply(z, x))\n",
      "Ite(Eq(z, z), Multiply(z, z), Multiply(z, y))\n",
      "Ite(Eq(z, z), Multiply(z, z), Multiply(z, z))\n"
     ]
    }
   ],
   "source": [
    "expr_asts: [ast.AstNode] = []\n",
    "bool_asts: [ast.AstNode] = []\n",
    "\n",
    "def gen_all():\n",
    "    global expr_asts, bool_asts\n",
    "    new_expr_asts = [ast.c1, ast.c2, ast.c3, ast.x, ast.y, ast.z]\n",
    "    new_bool_asts = []\n",
    "    for s in expr_asts:\n",
    "        for t in expr_asts:\n",
    "            new_expr_asts.append(ast.Add(s, t))\n",
    "            new_expr_asts.append(ast.Multiply(s, t))\n",
    "            new_bool_asts.append(ast.Lt(s, t))\n",
    "            new_bool_asts.append(ast.Eq(s, t))\n",
    "    for p in bool_asts:\n",
    "        new_bool_asts.append(ast.Not(p))\n",
    "        for q in bool_asts:\n",
    "            new_bool_asts.append(ast.And(p, q))\n",
    "            new_bool_asts.append(ast.Or(p, q))\n",
    "        for s in expr_asts:\n",
    "            for t in expr_asts:\n",
    "                new_expr_asts.append(ast.Ite(p, s, t))\n",
    "    expr_asts = new_expr_asts\n",
    "    bool_asts = new_bool_asts\n",
    "\n",
    "gen_all()\n",
    "gen_all()\n",
    "gen_all()\n",
    "\n",
    "expr_asts.sort()\n",
    "bool_asts.sort()\n",
    "\n",
    "print(len(expr_asts))\n",
    "for s in expr_asts[:10]:\n",
    "    print(s)\n",
    "print('...')\n",
    "for s in expr_asts[-5:]:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [0, 1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59,\n",
    "        61, 67, 71, 73, 79, 83, 89, 97]\n",
    "nums += [-n for n in nums[1:]]\n",
    "r = random.Random(53)\n",
    "\n",
    "if False:\n",
    "    best_d = ()\n",
    "    best_d_vals = {}\n",
    "\n",
    "    for i in range(10):\n",
    "        d = (r.choice(nums), r.choice(nums), r.choice(nums))\n",
    "        vals = {}\n",
    "        e = ast.Env(*d)\n",
    "        for s in expr_asts:\n",
    "            v = (s.eval(e),)\n",
    "            if v not in vals:\n",
    "                vals[v] = []\n",
    "            vals[v].append(s)\n",
    "        if len(vals) > len(best_d_vals):\n",
    "            best_d = d\n",
    "            best_d_vals = vals\n",
    "\n",
    "    print(\"%r: %d\" % (best_d, len(best_d_vals)))\n",
    "\n",
    "    for i in range(4):\n",
    "        next_best_d = ()\n",
    "        next_best_d_vals = {}\n",
    "        for j in range(10):\n",
    "            d = best_d + ((r.choice(nums), r.choice(nums), r.choice(nums)),)\n",
    "            vals = {}\n",
    "            e = ast.Env(*(d[-1]))\n",
    "            for v, ss in best_d_vals.items():\n",
    "                for s in ss:\n",
    "                    cv = v + (s.eval(e),)\n",
    "                    if cv not in vals:\n",
    "                        vals[cv] = []\n",
    "                    vals[cv].append(s)\n",
    "            if len(vals) > len(next_best_d_vals):\n",
    "                next_best_d = d\n",
    "                next_best_d_vals = vals\n",
    "        best_d = next_best_d\n",
    "        best_d_vals = next_best_d_vals\n",
    "        print('%d, %d: %r => %d' % (i, j, best_d, len(best_d_vals)))\n",
    "\n",
    "    print('Discriminators %r:\\n  yield %d classes' % (best_d, len(best_d_vals)))\n",
    "    del best_d_vals\n",
    "\n",
    "else:\n",
    "    best_d = ((-61, -13, 79), (-43, 67, -11), (67, -47, -43),\n",
    "              (-5, -83, -83),\n",
    "              (1, 11, 59), (13, 1, 71), (19, 73, 1),\n",
    "              (2, 97, 23), (89, 2, 29), (79, 31, 2),\n",
    "              (3, 7, 83), (17, 3, 67), (23, 61, 3),\n",
    "              (5, 7, 7), (17, 5, 17), (23, 23, 5),\n",
    "              (13, 13, 13),\n",
    "              )\n",
    "\n",
    "d_envs = [ast.Env(*d) for d in best_d]\n",
    "\n",
    "def at_boundary(i, total, divs):\n",
    "    return i * divs // total < (i + 1) * divs // total\n",
    "\n",
    "progress_count = 0\n",
    "progress_total = 1\n",
    "\n",
    "def progress_start(total):\n",
    "    global progress_count, progress_total\n",
    "    progress_count = 0\n",
    "    progress_total = total\n",
    "\n",
    "def progress_next():\n",
    "    global progress_count, progress_total\n",
    "    assert progress_count < progress_total\n",
    "    if progress_count >= progress_total:\n",
    "        return\n",
    "    if at_boundary(progress_count, progress_total, 100):\n",
    "        if at_boundary(progress_count, progress_total, 10):\n",
    "            print('%d%%' % ((progress_count + 1) * 100 // len(expr_asts),), end='')\n",
    "        else:\n",
    "            print('.', end='')\n",
    "    progress_count += 1\n",
    "    if progress_count >= progress_total:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........10%.........20%.........30%.........40%.........50%.........60%.........70%.........80%.........90%.........100%\n"
     ]
    }
   ],
   "source": [
    "progress_start(len(expr_asts))\n",
    "for i in range(len(expr_asts)):\n",
    "    s = expr_asts[i]\n",
    "    canon_ast = s.canonical()\n",
    "    if canon_ast is not s:\n",
    "        if not sp.ask(sp.Q.eq(s.to_sym(), s.canonical().to_sym())):\n",
    "            print('Not equivalent: %s <-> %s' % (s, s.canonical()))\n",
    "    progress_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EquivalenceClass:\n",
    "    ident: any\n",
    "    rep: ast.AstNode\n",
    "    members: [ast.AstNode]\n",
    "\n",
    "    def __init__(self, ident):\n",
    "        self.ident = ident\n",
    "        self.rep = None\n",
    "        self.members = []\n",
    "\n",
    "    def ensure(self, a: ast.AstNode):\n",
    "        assert a is a.canonical()\n",
    "        if self.rep is None:\n",
    "            self.rep = a\n",
    "        self.members.append(a)\n",
    "\n",
    "\n",
    "class Equivalence:\n",
    "    equivs: [EquivalenceClass]\n",
    "    idents: {any: int}\n",
    "    known: {str: int}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.equivs = []\n",
    "        self.idents = {}\n",
    "        self.known = {}\n",
    "\n",
    "    def _compute_ident(self, a: ast.AstNode, hints: [ast.AstNode]):\n",
    "        assert False\n",
    "\n",
    "    def _arbitrary_new_ident(self):\n",
    "        return len(self.equivs)\n",
    "\n",
    "    def equiv(self, a: ast.AstNode, hints: [ast.AstNode] = []):\n",
    "        # canonicalize before doing any checks\n",
    "        a_canon = a.canonical()\n",
    "        a_s = str(a_canon)\n",
    "        # early-out if we have already seen this (canonical) a\n",
    "        if a_s in self.known:\n",
    "            return self.equivs[self.known[a_s]]\n",
    "        # otherwise compute its class ident\n",
    "        a_i = self._compute_ident(a_canon, hints)\n",
    "        if a_i in self.idents:\n",
    "            # this class ident already known, return existing\n",
    "            n = self.idents[a_i]\n",
    "            a_c = self.equivs[n]\n",
    "        else:\n",
    "            # this class ident not known, make a new one\n",
    "            a_c = EquivalenceClass(a_i)\n",
    "            n = len(self.equivs)\n",
    "            self.idents[a_i] = n\n",
    "            self.equivs.append(a_c)\n",
    "        a_c.ensure(a_canon)\n",
    "        self.known[a_s] = n\n",
    "        return self.equivs[n]\n",
    "\n",
    "    def tidy(self):\n",
    "        for e in self.equivs:\n",
    "            e.members.sort()\n",
    "            e.rep = e.members[0]\n",
    "\n",
    "\n",
    "class DiscrimEquiv(Equivalence):\n",
    "    def _compute_ident(self, a_canon: ast.AstNode, hints: [ast.AstNode]):\n",
    "        global d_envs\n",
    "        return tuple((a_canon.eval(e) for e in d_envs))\n",
    "\n",
    "\n",
    "class SymEquiv(Equivalence):\n",
    "    subeq: DiscrimEquiv\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.subeq = DiscrimEquiv()\n",
    "\n",
    "    def _compute_ident(self, a_canon: ast.AstNode, hints: [ast.AstNode]):\n",
    "        a_sym = a_canon.to_sym()\n",
    "        # check the hints first\n",
    "        for h in hints:\n",
    "            h_s = str(h.canonical())\n",
    "            if h_s in self.known:\n",
    "                c = self.equivs[self.known[h_s]]\n",
    "                # symbolic equivalence check still required to confirm\n",
    "                c_sym = c.rep.to_sym()\n",
    "                if sp.ask(sp.Q.eq(a_sym, c_sym)):\n",
    "                    return c.ident\n",
    "                else:\n",
    "                    print(\"bad equivalence hint: %s == %s\" % (a_canon, h_s))\n",
    "        # check discriminator equivalence\n",
    "        sub_c = self.subeq.equiv(a_canon)\n",
    "        if len(sub_c.members) == 1:\n",
    "            assert sub_c.members[0] is a_canon\n",
    "            # discriminator equivalence not found, we are unique\n",
    "            return self._arbitrary_new_ident()\n",
    "        # slower checks -- first check structural equivalence\n",
    "        # recursive self.equiv means sub_c.members might grow while we iterate\n",
    "        i = 0\n",
    "        while i < len(sub_c.members):\n",
    "            m = sub_c.members[i]\n",
    "            i += 1\n",
    "            # this expr will have been added to sub_c while being checked\n",
    "            if m is a_canon:\n",
    "                continue\n",
    "            # if these are the same operation, and all operands are equivalent,\n",
    "            # they are equivalent\n",
    "            if a_canon.name == m.name:\n",
    "                assert len(a_canon.p) == len(m.p)\n",
    "                for a_p, m_p in zip(a_canon.p, m.p):\n",
    "                    if self.equiv(a_p) is not self.equiv(m_p):\n",
    "                        break\n",
    "                else:\n",
    "                    # definitely equivalent!\n",
    "                    m_s = str(m)\n",
    "                    assert m_s in self.known\n",
    "                    return self.equivs[self.known[m_s]].ident\n",
    "        # if symbolic forms can be proven equal, they are equivalent\n",
    "        for m in sub_c.members:\n",
    "            if m is a_canon:\n",
    "                continue\n",
    "            m_sym = m.to_sym()\n",
    "            if sp.ask(sp.Q.eq(a_sym, m_sym)):\n",
    "                return self.equivs[self.known[str(m)]].ident\n",
    "        # otherwise, we must assume this is a new class\n",
    "        return self._arbitrary_new_ident()\n",
    "\n",
    "    def tidy(self):\n",
    "        self.subeq.tidy()\n",
    "        super().tidy()\n",
    "\n",
    "\n",
    "symeq = SymEquiv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building equivalence classes\n",
      ".........10%.........20%.........30%.........40%.........50%.........60%.........70%.........80%.........90%.........100%\n",
      "Canonicalizing equivalence classes\n",
      "29635 equivalence classes in subeq approximation\n",
      "36734 equivalence classes in symbolic equivalence\n",
      "Writing known equivalences\n",
      ".........10%.........20%.........30%.........40%.........50%.........60%.........70%.........80%.........90%.........100%\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    print(\"Reading known equivalences\")\n",
    "    with open('output/eqclasses.txt', 'r') as f:\n",
    "        lines = list(f.readlines())\n",
    "    known_equivs = {}\n",
    "    progress_start(len(lines))\n",
    "    for l in lines:\n",
    "        m = re.match('^(.*) -> new$', l)\n",
    "        if m:\n",
    "            s = m.group(1)\n",
    "            s_ex = ast.parse_expr_str(s)\n",
    "            known_equivs[s] = symeq.equiv(s_ex).rep\n",
    "        else:\n",
    "            m = re.match('^(.*) == (.*)$', l)\n",
    "            if m:\n",
    "                s = m.group(1)\n",
    "                t = m.group(2)\n",
    "                if t in known_equivs:\n",
    "                    s_ex = ast.parse_expr_str(s)\n",
    "                    known_equivs[s] = symeq.equiv(s_ex, hints=[known_equivs[t]]).rep\n",
    "        progress_next()\n",
    "\n",
    "if True:\n",
    "    print(\"Building equivalence classes\")\n",
    "    progress_start(len(expr_asts))\n",
    "    for s in expr_asts:\n",
    "        c = symeq.equiv(s)\n",
    "        progress_next()\n",
    "\n",
    "print(\"Canonicalizing equivalence classes\")\n",
    "symeq.tidy()\n",
    "\n",
    "print('%d equivalence classes in subeq approximation' % (len(symeq.subeq.equivs),))\n",
    "print('%d equivalence classes in symbolic equivalence' % (len(symeq.equivs),))\n",
    "\n",
    "print(\"Writing known equivalences\")\n",
    "if True:\n",
    "    with open('output/eqclasses.txt', 'w') as f:\n",
    "        progress_start(len(expr_asts))\n",
    "        for s in expr_asts:\n",
    "            c = symeq.equiv(s)\n",
    "            if s == c.rep:\n",
    "                res = '%s -> new' % (s,)\n",
    "            else:\n",
    "                res = '%s == %s' % (s, c.rep)\n",
    "            f.write(res + '\\n')\n",
    "            f.flush()\n",
    "            progress_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add(2, 3)\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "s = ast.parse_expr_str('Add(1, Add(1, 3))')\n",
    "c = symeq.equiv(s)\n",
    "print(str(c.rep))\n",
    "print(c.rep < s)\n",
    "print(s < c.rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
